{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tokenizer import FilteredTokenizer\n",
    "from embedding import WordEmbedding\n",
    "from config import EMBEDDING_PATH, EMBEDDING_FNAME, DATA_PATH, RAW_DATA\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATA_PATH, RAW_DATA)\n",
    "df = pd.read_csv(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129971"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = df['description'].tolist()\n",
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FT = FilteredTokenizer()\n",
    "Tokens = FT.filter_and_tokenize(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching in /Users/AndyKwan/Documents/data science/word_embedding/wiki-news-300d-1M.vec for word vector file ...\n",
      "Using pretrained embedding, it may take some time ...\n"
     ]
    }
   ],
   "source": [
    "fasttext_word_embedding = WordEmbedding()\n",
    "fasttext_word_embedding.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Embedding coverage ...\n"
     ]
    }
   ],
   "source": [
    "matched_token, unmatched_token = fasttext_word_embedding.check_embedding_coverage(list_tokens=Tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.751591145992279), ('monarch', 0.6741327047348022), ('princess', 0.6713887453079224), ('kings', 0.669899046421051), ('kingdom', 0.5971317887306213), ('royal', 0.5921063423156738), ('uncrowned', 0.5911506414413452), ('prince', 0.5909028649330139), ('lady', 0.5904011726379395), ('monarchs', 0.5884358286857605)]\n",
      "[('didnt', 0.7912282943725586), ('doesnt', 0.7744663953781128), ('wont', 0.7738192081451416), ('wouldnt', 0.7669345736503601), ('cant', 0.7571746706962585), ('Dont', 0.7333537340164185), ('donot', 0.7325714826583862), ('shouldnt', 0.723484456539154), ('dosnt', 0.6950490474700928), ('dnt', 0.6921104192733765)]\n",
      "[('another', 0.7364089488983154), ('the', 0.7042925357818604), ('one', 0.6761847734451294), ('only', 0.6591331958770752), ('very', 0.6515913009643555), ('just', 0.6320288777351379), ('second', 0.628737211227417), ('some', 0.626456618309021), ('first', 0.6264200210571289), ('having', 0.6240551471710205)]\n"
     ]
    }
   ],
   "source": [
    "print(fasttext_word_embedding.embeddings.most_similar(positive=['woman', 'king'], negative=['man']))\n",
    "print(fasttext_word_embedding.embeddings.most_similar(\"dont\"))\n",
    "print(fasttext_word_embedding.embeddings.most_similar(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.91236160199567"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_word_embedding.coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('didnt', 0.7912282943725586), ('doesnt', 0.7744663953781128), ('wont', 0.7738192081451416), ('wouldnt', 0.7669345736503601), ('cant', 0.7571746706962585), ('Dont', 0.7333537340164185), ('donot', 0.7325714826583862), ('shouldnt', 0.723484456539154), ('dosnt', 0.6950490474700928), ('dnt', 0.6921104192733765)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(fasttext_word_embedding.embeddings.most_similar(\"dont\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('girl', 0.8618075847625732), ('boys', 0.7724494934082031), ('lad', 0.7691618800163269), ('kid', 0.7604904174804688), ('teenager', 0.7135519981384277), ('youngster', 0.7107733488082886), ('12-year-old', 0.6984817385673523), ('child', 0.6959749460220337), ('man', 0.6806782484054565), ('13-year-old', 0.6773315668106079)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(fasttext_word_embedding.embeddings.most_similar(\"boy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "T = Transformer(fasttext_word_embedding.wordvec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['points'].tolist()\n",
    "# the part of y is not done yet\n",
    "X = T.fit_transform(Tokens, y, drop_long_sentences=50, drop_short_sentences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129971, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09575379, -0.19282483, -0.33506775, ...,  0.44551393,\n",
       "         0.13186015, -0.12090211],\n",
       "       [-0.13480206, -0.1262789 , -0.06169289, ...,  0.47900543,\n",
       "         0.10493672, -0.12836915],\n",
       "       [-0.01410749, -0.2044175 , -0.24836826, ...,  0.4760725 ,\n",
       "         0.0952632 , -0.10150274],\n",
       "       ...,\n",
       "       [ 0.0080526 , -0.03614132, -0.12907189, ...,  0.31180683,\n",
       "         0.22032477, -0.09592054],\n",
       "       [-0.1049885 , -0.06577354, -0.04807729, ...,  0.23851076,\n",
       "         0.12913962, -0.09954742],\n",
       "       [-0.0451254 , -0.16707538, -0.16610186, ...,  0.44746676,\n",
       "         0.08057784, -0.12651043]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'vectorizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a3c7da115755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'vectorizer'"
     ]
    }
   ],
   "source": [
    "X.vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
